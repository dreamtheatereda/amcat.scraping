# -*- coding: utf-8 -*-
from __future__ import unicode_literals, print_function, absolute_import
###########################################################################
#          (C) Vrije Universiteit, Amsterdam (the Netherlands)            #
#                                                                         #
# This file is part of AmCAT - The Amsterdam Content Analysis Toolkit     #
#                                                                         #
# AmCAT is free software: you can redistribute it and/or modify it under  #
# the terms of the GNU Affero General Public License as published by the  #
# Free Software Foundation, either version 3 of the License, or (at your  #
# option) any later version.                                              #
#                                                                         #
# AmCAT is distributed in the hope that it will be useful, but WITHOUT    #
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or   #
# FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public     #
# License for more details.                                               #
#                                                                         #
# You should have received a copy of the GNU Affero General Public        #
# License along with AmCAT.  If not, see <http://www.gnu.org/licenses/>.  #
###########################################################################

"""
Scrapes any object which matches query, aswell as any post or comment inside any of those objects.
Objects can be people, pages, events, applications, groups, places.
"""


from amcat.scraping.document import Document, HTMLDocument, IndexDocument


from urllib import urlencode
#from urlparse import urljoin
from amcat.tools.toolkit import readDate

import json

START_URL = "https://graph.facebook.com/search?q={q}&access_token=AAAAAAITEghMBAJ2EOwzoUay6yikk1fP5Sa9HAl8hVFW8f2BRBiW8JyaTwImTZB5IhrzY1IU7kGUkPFv5HJi7L0FXyyC4VSnWoWQ4fZBENCb7U1XnJi"
LOGIN_URL = "https://facebook.com"
TYPES = set()

from django import forms
from amcat.scraping.scraper import HTTPScraper,DBScraper,DBScraperForm

class SearchResult(object):
    def __init__(self,data,url):
        self.data = data
        self.url = url
    def __str__(self):
        return self.url


class FacebookQueryForm(DBScraperForm):
    query = forms.CharField()

class FacebookQueryScraper(HTTPScraper, DBScraper):
    options_form = FacebookQueryForm
    medium_name = "Facebook"

    def __init__(self, *args, **kwargs):
        super(FacebookQueryScraper, self).__init__(*args, **kwargs)

    def _login(self, username, password):
        self.open(LOGIN_URL) #cookies
        POST_DATA = {
            'email' : username,
            'pass' : password
            }
        result = self.open(LOGIN_URL, urlencode(POST_DATA))

    def _get_units(self):
        next_url = START_URL.format(q=self.options['query'])
        print(next_url)
        while True:
            _json = self.open(next_url).read()
            data = json.loads(_json)
            yield SearchResult(data,next_url)
            next_url = data['paging']['next']
            print(TYPES)
            
        
    def _scrape_unit(self, _data): 

        # (i)page properties: 
        # bytes, page, category, any of the article props

        # article properties: 
        # date, section, pagenr, headline, byline, length (autogenerated),
        # url (already present), text, parent, medium (auto), author

        for data in _data.data['data']: # lol
            _type = data['type']
            TYPES.add(_type)
            if _type == "status":
                obj = Document()
            elif _type == "photo" or _type == "video":
                obj = Document()
                if 'name' in data:
                    obj.props.headline = data['name']
            elif _type == "event":
                obj = Document()
                print("\nEVENT\n")
            elif _type == "link":
                obj = Document()

            obj.props.date = readDate(data['created_time'])
            obj.props.author = "{}, {}".format(data['from']['name'],data['from']['id'])
            if 'message' in data:
                obj.props.text = data['message']
            elif 'description' in data:
                obj.props.text = data['description']
            elif 'story' in data:
                obj.props.text = data['story']
            elif 'caption' in data:
                obj.props.text = data['caption']
            else:
                obj.props.text = None
            obj.props.type = _type
        
            obj.props.all_data = data

            yield obj


if __name__ == '__main__':
    from amcat.scripts.tools import cli
    from amcat.tools import amcatlogging
    amcatlogging.debug_module("amcat.scraping.scraper")
    amcatlogging.debug_module("amcat.scraping.document")
    cli.run_cli(FacebookQueryScraper)

